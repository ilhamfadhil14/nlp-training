{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\", \"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 2, 'man': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary for indexing\n",
    "vocab = {}\n",
    "count = 0\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            count += 1\n",
    "            vocab[word] = count\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_vector(somestring):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab) # create array contains 0 in length of vocab\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]-1] = 1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man bites dog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(processed_docs[1])\n",
    "get_onehot_vector(processed_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_onehot_vector(\"man and dog are good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dog', 'bites', 'man'], ['man', 'bites', 'dog'], ['dog', 'eats', 'meat'], ['man', 'eats', 'food']]\n",
      "['dog', 'bites', 'man', 'man', 'bites', 'dog', 'dog', 'eats', 'meat', 'man', 'eats', 'food']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for sentence in processed_docs:\n",
    "    data.append(sentence.split())\n",
    "\n",
    "print(data)\n",
    "\n",
    "values = []\n",
    "\n",
    "for sentence in processed_docs:\n",
    "    temp = sentence.split()\n",
    "    values = values + temp\n",
    "\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoded :  [1 0 4 4 0 1 1 2 5 4 2 3]\n",
      "Onehot Encoded Matrix:\n",
      " [[1. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Label Encoded : \", integer_encoded)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(data).toarray()\n",
    "print(\"Onehot Encoded Matrix:\\n\", one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
      "Vocabulary : {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "BoW for : dog bites man :  [[1 1 0 0 1 0]]\n",
      "BoW for : man bites dog :  [[1 1 0 0 1 0]]\n",
      "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"Data :\", processed_docs)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "print(\"Vocabulary :\", count_vect.vocabulary_)\n",
    "\n",
    "print(\"BoW for : \" + processed_docs[0] + \" : \", bow_rep[0].toarray())\n",
    "print(\"BoW for : \" + processed_docs[1] + \" : \", bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary : {'dog bites': 2, 'bites man': 1, 'man bites': 6, 'bites dog': 0, 'dog eats': 3, 'eats meat': 5, 'man eats': 7, 'eats food': 4}\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "print(\"Vocabulary :\", count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW representation for : dog bites man :  [[0 1 1 0 0 0 0 0]]\n",
      "BoW representation for : man bites dog :  [[1 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print('BoW representation for : ' + processed_docs[0] + \" : \", bow_rep[0].toarray())\n",
    "print('BoW representation for : ' + processed_docs[1] + \" : \", bow_rep[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog bites': 2,\n",
       " 'bites man': 1,\n",
       " 'man bites': 6,\n",
       " 'bites dog': 0,\n",
       " 'dog eats': 3,\n",
       " 'eats meat': 5,\n",
       " 'man eats': 7,\n",
       " 'eats food': 4}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF for all words in the vocabulary [1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "print(\"IDF for all words in the vocabulary\", tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words in the vocabulary ['bites' 'dog' 'eats' 'food' 'man' 'meat']\n"
     ]
    }
   ],
   "source": [
    "print(\"All words in the vocabulary\", tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF representation for all documents in the corpus\n",
      " [[0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
      " [0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
      " [0.         0.44809973 0.55349232 0.         0.         0.70203482]\n",
      " [0.         0.         0.55349232 0.70203482 0.44809973 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF representation for all documents in the corpus\\n\", bow_rep_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf representation for 'dog and man are friends':\n",
      " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8164b79054baafd32ac16b5e9f459bd79fbb7f855c6bedf6f48d0e0c944eb799"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
